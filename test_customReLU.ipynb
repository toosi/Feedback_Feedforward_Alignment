{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import init\n",
    "import torch.autograd as autograd\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "\n",
    "import copy\n",
    "import numpy as np\n",
    "import scipy.stats as ss\n",
    "import scipy\n",
    "import h5py\n",
    "import random\n",
    "import argparse\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import warnings\n",
    "from torch.nn.modules.utils import _single, _pair\n",
    "import math\n",
    "import copy\n",
    "# do crazy end-to-end optimization of backward path with MNIST/CIFAR10 and nn.linear    \n",
    "# when calling loss.backward both gradinet_weight and grad_weight_feedback are being computed in customized modules\n",
    "# first control against BP and regular modules\n",
    "# Linear from here :https://pytorch.org/docs/stable/notes/extending.html\n",
    "# Conv from here: https://github.com/pytorch/pytorch/blob/master/torch/nn/grad.py    \n",
    "# autograd : https://pytorch.org/docs/stable/autograd.html#torch.autograd.backward  \n",
    "\n",
    "class ReLUBFunction(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    ReLUB (ReLU Back) is a nonlinearity interms of input2 which is used in \n",
    "    backward path\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, input2):\n",
    "        \"\"\"\n",
    "        In the forward pass we receive a Tensor containing the input and return\n",
    "        a Tensor containing the output. ctx is a context object that can be used\n",
    "        to stash information for backward computation. You can cache arbitrary\n",
    "        objects for use in the backward pass using the ctx.save_for_backward method.\n",
    "        \"\"\"\n",
    "        ctx.save_for_backward(input, input2)\n",
    "        input[input2<0] = 0\n",
    "        return input #input.clamp(min=0)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\"\n",
    "        In the backward pass we receive a Tensor containing the gradient of the loss\n",
    "        with respect to the output, and we need to compute the gradient of the loss\n",
    "        with respect to the input.\n",
    "        \"\"\"\n",
    "        input, input2, = ctx.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        grad_input[input2 < 0] = 0\n",
    "        return grad_input, None\n",
    "\n",
    "class ReLUB(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ReLUB, self).__init__()\n",
    "    \n",
    "    def forward(self, input, input2):\n",
    "        return ReLUBFunction.apply(input, input2)#, input2.clamp(min=0).detach()\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "# from modules import customized_modules_simple as customized_modules\n",
    "from modules import BiHebb_modules as customized_modules  # used for NeuIPS2020\n",
    "\n",
    "Linear = customized_modules.Linear\n",
    "ReLU = nn.ReLU() #customized_modules.ReLU\n",
    "\n",
    "# class FullyConnectedF(nn.Module):\n",
    "#     def __init__(self, algorithm):\n",
    "#         super(FullyConnectedF, self).__init__()\n",
    "#         input_length = 1024\n",
    "#         self.fc_0 = Linear(input_length,256,False, algorithm=algorithm)\n",
    "#         self.fc_1 = Linear(256,256,False, algorithm=algorithm)\n",
    "#         self.fc_2 = Linear(256,10,False, algorithm=algorithm)\n",
    "#         self.relu = ReLU\n",
    "       \n",
    "#     def forward(self,x):\n",
    "#         x = self.relu(self.fc_0(x))\n",
    "#         x = self.relu(self.fc_1(x))\n",
    "#         x = self.relu(self.fc_2(x))\n",
    "       \n",
    "#         return x, x # just to satisfy the requirements\n",
    "\n",
    "          \n",
    "\n",
    "# class FullyConnectedB(nn.Module):\n",
    "#     def __init__(self, hidden_layers, nonlinearfunc, input_length, algorithm):\n",
    "#         super(FullyConnectedB, self).__init__()\n",
    "#         input_length = 1024\n",
    "#         self.fc_0 = Linear(256, input_length,False, algorithm=algorithm)\n",
    "#         self.fc_1 = Linear(256,256,False, algorithm=algorithm)\n",
    "#         self.fc_2 = Linear(10,256,False, algorithm=algorithm)\n",
    "#         self.relu = ReLUB\n",
    "       \n",
    "#     def forward(self,x):\n",
    "        \n",
    "#         x = self.relu(self.fc_2(x))\n",
    "#         x = self.relu(self.fc_1(x))\n",
    "#         x = self.relu(self.fc_0(x))\n",
    "#         return x, x # just to satisfy the requirements (the first one shoudl be V1 layer)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "if socket.gethostname()[0:4] in  ['node','holm','wats']:\n",
    "    path_prefix = '/rigel/issa/users/Tahereh/Research'\n",
    "elif socket.gethostname() == 'SYNPAI':\n",
    "    path_prefix = '/hdd6gig/Documents/Research'\n",
    "elif socket.gethostname()[0:2] == 'ax':\n",
    "    path_prefix = '/scratch/issa/users/tt2684/Research'\n",
    "    plt.switch_backend('agg')\n",
    "elif socket.gethostname() == 'turing':\n",
    "    path_prefix = '/home/tahereh/Documents/Research'\n",
    "\n",
    "\n",
    "imagesetdir = path_prefix+'/Data/'\n",
    "resultsdir = path_prefix+'/Results/Toy_models/'\n",
    "\n",
    "class Args:\n",
    "    dum=None\n",
    "\n",
    "args = Args()\n",
    "args.batch_size=256\n",
    "args.no_cuda = False\n",
    "args.seed = 0\n",
    "\n",
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "use_cuda = True\n",
    "# data loader\n",
    "kwargs = {'num_workers': 0, 'pin_memory': True, 'drop_last':True} if use_cuda else {}\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(imagesetdir, train=True, download=True,\n",
    "                    transform=transforms.Compose([\n",
    "                        transforms.RandomAffine(degrees=20, translate=(0.1, 0.1),scale=(0.25,2) ),\n",
    "                        transforms.Resize(32),\n",
    "                        transforms.ToTensor(),\n",
    "                       \n",
    "                    ])),\n",
    "    batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(imagesetdir, train=False, transform=transforms.Compose([\n",
    "                        transforms.RandomAffine(degrees=20, translate=(0.1, 0.1),scale=(0.25,2) ),\n",
    "                        transforms.Resize(32),\n",
    "                        transforms.ToTensor(),\n",
    "                        \n",
    "                    ])),\n",
    "    batch_size=args.batch_size, shuffle=False, **kwargs)\n",
    "\n",
    "# transforms.Normalize((0.1307,), (0.3081,))\n",
    "n_layers = 3\n",
    "n_dataloader = 100000\n",
    "batch_size = args.batch_size\n",
    "\n",
    "\n",
    "# class ReLUGrad(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(ReLUGrad, self).__init__()\n",
    "#     def forward(self, grad_output, input):\n",
    "#         grad_input = grad_output.clone()\n",
    "#         grad_input[input < 0] = 0\n",
    "#         return grad_input\n",
    "\n",
    "class Forward(nn.Module):\n",
    "    def __init__(self, algorithm):\n",
    "        super(Forward, self).__init__()\n",
    "        self.fc_0 = Linear(1024, 256, bias=False, algorithm=algorithm)\n",
    "        self.fc_1 = Linear(256, 256, bias=False, algorithm=algorithm)\n",
    "        self.fc_2 = Linear(256, 10, bias=False, algorithm=algorithm)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        xrelu0 = self.fc_0(x)\n",
    "        x0 = self.relu(xrelu0)\n",
    "        xrelu1 = self.fc_1(x0)\n",
    "        x1 = self.relu(xrelu1)\n",
    "        x2 = self.fc_2(x1)\n",
    "\n",
    "        return x2 , [x, x0, x1, x2], [xrelu1, xrelu0]\n",
    "\n",
    "class Backward(nn.Module):\n",
    "    def __init__(self, algorithm):\n",
    "        super(Backward, self).__init__()\n",
    "        self.fc_2 = Linear(10, 256, bias=False, algorithm=algorithm)\n",
    "        self.fc_1 = Linear(256, 256, bias=False, algorithm=algorithm)\n",
    "        self.fc_0 = Linear(256, 1024, bias=False, algorithm=algorithm)\n",
    "        self.grelu = ReLUB()\n",
    "\n",
    "    def forward(self, x, xrelus):\n",
    "        x2 = self.fc_2(x)\n",
    "        x2 = self.grelu(x2, xrelus[0])\n",
    "        x1 = self.fc_1(x2)\n",
    "        x1 = self.grelu(x1, xrelus[1])\n",
    "        x0 = self.fc_0(x1)\n",
    "\n",
    "        return x0, [x2, x1,  x]\n",
    "\n",
    "# class Backward(nn.Module):\n",
    "#     def __init__(self, algorithm):\n",
    "#         super(Backward, self).__init__()\n",
    "#         self.fc_2 = Linear(10, 256, bias=False, algorithm=algorithm)\n",
    "#         self.fc_1 = Linear(256, 256, bias=False, algorithm=algorithm)\n",
    "#         self.fc_0 = Linear(256, 1024, bias=False, algorithm=algorithm)\n",
    "#         self.relu = nn.ReLU()\n",
    "\n",
    "#     def forward(self, x, xrelus):\n",
    "#         x2 = self.fc_2(x)\n",
    "#         x2 = self.relu(x2)\n",
    "#         x1 = self.fc_1(x2)\n",
    "#         x1 = self.relu(x1)\n",
    "#         x0 = self.fc_0(x1)\n",
    "\n",
    "#         return x0, [x2, x1,  x]\n",
    "\n",
    "def transpose_weights(state_dict):\n",
    "\n",
    "    state_dict_new = {}\n",
    "    for k, item in state_dict.items():\n",
    "        state_dict_new.update({k: item.t()})\n",
    "    return state_dict_new\n",
    "\n",
    "\n",
    "def correlation(output, images):\n",
    "    \"\"\"Computes the correlation between reconstruction and the original images\"\"\"\n",
    "    x = output.contiguous().view(-1)\n",
    "    y = images.contiguous().view(-1) \n",
    "\n",
    "    vx = x - torch.mean(x)\n",
    "    vy = y - torch.mean(y)\n",
    "\n",
    "    pearson_corr = torch.sum(vx * vy) / (torch.sqrt(torch.sum(vx ** 2)) * torch.sqrt(torch.sum(vy ** 2)))\n",
    "    return pearson_corr.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = 'FA' #'BP'\n",
    "modelF = Forward(algorithm=algorithm).cuda() # main model\n",
    "modelB = Backward(algorithm=algorithm).cuda() # backward network to compute gradients for modelF\n",
    "\n",
    "modelC = Forward(algorithm=algorithm).cuda() # Forward Control model to compare to BP\n",
    "modelC.load_state_dict(modelF.state_dict())\n",
    "# start symmetric\n",
    "# modelB.load_state_dict(transpose_weights(modelF.state_dict()) )\n",
    "modelE = Forward(algorithm=algorithm).cuda()\n",
    "\n",
    "modelF_untrained = modelF.state_dict()\n",
    "modelB_untrained = modelB.state_dict()\n",
    "modelC_untrained = modelC.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'state': {}, 'param_groups': [{'lr': 0.001, 'momentum': 0, 'alpha': 0.99, 'eps': 1e-08, 'centered': False, 'weight_decay': 0.0001, 'params': [139746300707904, 139746300707584, 139746300708864]}]}\n",
      "0 0.3542507990048482 0.5586605235042735\n",
      "tensor(11.3620, device='cuda:0', grad_fn=<NormBackward0>)\n",
      "1 0.33724967243834436 0.6285223023504274\n",
      "tensor(13.3041, device='cuda:0', grad_fn=<NormBackward0>)\n",
      "2 0.32985374573458975 0.7297509348290598\n",
      "tensor(14.7630, device='cuda:0', grad_fn=<NormBackward0>)\n",
      "3 0.3315411569216313 0.7608673878205128\n",
      "tensor(15.9823, device='cuda:0', grad_fn=<NormBackward0>)\n",
      "4 0.32991868703283816 0.7784788995726496\n",
      "tensor(17.0077, device='cuda:0', grad_fn=<NormBackward0>)\n",
      "5 0.3241402432959304 0.7949719551282052\n",
      "tensor(17.8578, device='cuda:0', grad_fn=<NormBackward0>)\n",
      "6 0.331319234182692 0.801582532051282\n",
      "tensor(18.5772, device='cuda:0', grad_fn=<NormBackward0>)\n",
      "7 0.3446260267852718 0.7157952724358975\n",
      "tensor(19.1652, device='cuda:0', grad_fn=<NormBackward0>)\n",
      "8 0.31799943681456083 0.8166566506410257\n",
      "tensor(19.6243, device='cuda:0', grad_fn=<NormBackward0>)\n",
      "9 0.32315517579897857 0.805839342948718\n",
      "tensor(20.0056, device='cuda:0', grad_fn=<NormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "algorithm = 'FA' #'BP'\n",
    "modelF = Forward(algorithm=algorithm).cuda() # main model\n",
    "modelB = Backward(algorithm=algorithm).cuda() # backward network to compute gradients for modelF\n",
    "\n",
    "modelC = Forward(algorithm=algorithm).cuda() # Forward Control model to compare to BP\n",
    "modelC.load_state_dict(modelF.state_dict())\n",
    "# start symmetric\n",
    "# modelB.load_state_dict(transpose_weights(modelF.state_dict()) )\n",
    "\n",
    "modelF.load_state_dict(modelF_untrained)\n",
    "modelB.load_state_dict(modelB_untrained)\n",
    "modelC.load_state_dict(modelC_untrained)\n",
    "\n",
    "optimizerC = optim.SGD(modelC.parameters(), lr=1e-1, weight_decay=1e-4)\n",
    "optimizerF = optim.RMSprop([p for n,p in modelF.named_parameters() if 'feedback' not in n],   lr=1e-3, weight_decay=1e-4)\n",
    "optimizerB = optim.RMSprop([p for n,p in modelB.named_parameters() if 'feedback' not in n],   lr=1e-3, weight_decay=1e-5)\n",
    "\n",
    "print(optimizerF.state_dict())\n",
    "\n",
    "criterionF = nn.CrossEntropyLoss() #\n",
    "criterionB = nn.MSELoss() #\n",
    "\n",
    "n_classes = 10\n",
    "onehot = torch.zeros(train_loader.batch_size, n_classes).cuda()\n",
    "\n",
    "\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    running_lossB = 0.0\n",
    "    running_corrB = 0.0\n",
    "    acc = 0.0\n",
    "    for images, targets in train_loader:\n",
    "        images = images.cuda()\n",
    "        targets = targets.cuda()\n",
    "\n",
    "        onehot = torch.zeros(train_loader.batch_size, n_classes).cuda()\n",
    "        onehot.zero_()\n",
    "        onehot.scatter_(1, targets.view(train_loader.batch_size,-1), 1)\n",
    "\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        out, interm, xrelu = modelF(images)\n",
    "        loss = criterionF(out, targets)\n",
    "\n",
    "        \n",
    "        optimizerF.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizerF.step()\n",
    "\n",
    "        # # SL\n",
    "        # modelB.load_state_dict(transpose_weights(modelF.state_dict()))\n",
    "        # out, interm, xrelu = modelF(images)\n",
    "        # recons, _ = modelB(out.detach() - onehot, xrelu)\n",
    "        # # recons, _ = modelB(out.detach(), xrelu)\n",
    "        # optimizerB.zero_grad()\n",
    "        # lossB = criterionB(recons, images)\n",
    "        # optimizerB.step()\n",
    "        # modelF.load_state_dict(transpose_weights(modelB.state_dict()))\n",
    "    # SL\n",
    "    modelB.load_state_dict(transpose_weights(modelF.state_dict()))\n",
    "    for images, targets in train_loader:\n",
    "        images = images.cuda()\n",
    "        targets = targets.cuda()\n",
    "\n",
    "        onehot = torch.zeros(train_loader.batch_size, n_classes).cuda()\n",
    "        onehot.zero_()\n",
    "        onehot.scatter_(1, targets.view(train_loader.batch_size,-1), 1)\n",
    "\n",
    "        images = images.view(images.shape[0], -1)\n",
    "\n",
    "\n",
    "        out, interm, xrelu = modelF(images)\n",
    "        # inputB = F.normalize(out.detach() -onehot) \n",
    "        inputB = out.detach() -onehot\n",
    "        inputB = (inputB - inputB.mean().expand_as(inputB))/inputB.std().expand_as(inputB)\n",
    "        recons, _ = modelB(inputB  , xrelu)\n",
    "        optimizerB.zero_grad()\n",
    "        lossB = criterionB(recons, images)\n",
    "        corrB = correlation(recons, images)\n",
    "        optimizerB.step()\n",
    "        modelF.load_state_dict(transpose_weights(modelB.state_dict()))\n",
    "        running_lossB += lossB.item()\n",
    "        running_corrB += corrB\n",
    "\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(out.data, 1)\n",
    "        acc += (predicted == targets).sum().item()/out.shape[0]\n",
    "\n",
    "    print(epoch, running_corrB/len(train_loader), acc/len(train_loader) )\n",
    "    print(torch.norm(modelF.fc_1.weight))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-44993ce23fb0>, line 1)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-44993ce23fb0>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    SL relu out-onehot\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "SL relu out-onehot\n",
    "0 0.4618158159602402 0.5472923344017094\n",
    "1 0.3776456688204382 0.6429453792735043\n",
    "2 0.32424116402100295 0.6848123664529915\n",
    "3 0.2554798854721917 0.736862313034188\n",
    "4 0.2367170939588139 0.7501502403846154\n",
    "5 0.2253640986278526 0.7605168269230769\n",
    "6 0.1854674427045716 0.7770599626068376\n",
    "7 0.20750007606469667 0.7900807959401709\n",
    "8 0.18773908040717116 0.8110142895299145\n",
    "9 0.1761054252075334 0.7721020299145299\n",
    "\n",
    "normalized\n",
    "0 0.42776161139337426 0.5583934294871795\n",
    "1 0.3757980693864007 0.662910657051282\n",
    "2 0.30473190571507836 0.7157618856837606\n",
    "3 0.25142446001116026 0.7382311698717948\n",
    "4 0.2510691239283635 0.7729200053418803\n",
    "5 0.22847212507174566 0.7751068376068376\n",
    "6 0.18480198078940058 0.7708333333333334\n",
    "7 0.17948726723846206 0.8119157318376068\n",
    "8 0.18290208426550922 0.8017661591880342\n",
    "9 0.1943849072369755 0.7871761485042735"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SL grelu out-onehot \n",
    "\n",
    "0 0.42766048727381945 0.5623831463675214\n",
    "1 0.37991426006341594 0.634498530982906\n",
    "2 0.34845178529747534 0.7121895032051282\n",
    "3 0.3395874370367099 0.7560263087606838\n",
    "4 0.3336598601860878 0.7611010950854701\n",
    "5 0.35095278893271065 0.7665097489316239\n",
    "6 0.34155619895865774 0.7979767628205128\n",
    "7 0.35036978558597404 0.8031016292735043\n",
    "8 0.3505960252040472 0.8009982638888888\n",
    "9 0.35636504822307163 0.8245025373931624\n",
    "\n",
    "0 0.42715904091158485 0.5602130074786325\n",
    "1 0.46117274819785714 0.6496728098290598\n",
    "2 0.41402703892980885 0.6952457264957265\n",
    "3 0.3697844798493589 0.7417367788461539\n",
    "4 0.34432112521085984 0.7130408653846154\n",
    "5 0.33250361477207935 0.7775941506410257\n",
    "6 0.33055557820022613 0.7970419337606838\n",
    "7 0.3220561359427933 0.8013321314102564\n",
    "8 0.33975157867639494 0.7974926549145299\n",
    "9 0.31651485297414994 0.8157719017094017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0 0.41600701009106433 0.5765391292735043\n",
    "1 0.3207030433874864 0.6105769230769231\n",
    "2 0.3144686948030423 0.7324051816239316\n",
    "3 0.31064027012922824 0.7684628739316239\n",
    "4 0.31330710076368773 0.7545072115384616\n",
    "5 0.3095823609166675 0.7602330395299145\n",
    "6 0.31068627396200454 0.8077256944444444\n",
    "7 0.321371576979629 0.8190938835470085\n",
    "8 0.3265181139238879 0.8200620993589743\n",
    "9 0.33742810187176764 0.8216980502136753"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0 0.0 0.435947516025641\n",
    "1 0.0 0.6284722222222222\n",
    "2 0.0 0.6996026976495726\n",
    "3 0.0 0.7355602297008547\n",
    "4 0.0 0.7592481303418803\n",
    "5 0.0 0.7737379807692307\n",
    "6 0.0 0.7885950854700855\n",
    "7 0.0 0.7981270032051282\n",
    "8 0.0 0.8041366185897436\n",
    "9 0.0 0.8107138087606838"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}